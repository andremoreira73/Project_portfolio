{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a14ab01",
   "metadata": {},
   "source": [
    "# Titanic Kaggle competition: classification problem\n",
    "\n",
    "Andre Moreira, 2023\n",
    "\n",
    "\n",
    "Based on materials from IBM's Data Science Professional Certificate (Pratiksha Verma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9d0201",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This Notebook is prepared in the simplest possible way to help beginners \"navigating\" some of the simpler classification models, how to use hyperparameter tuning, seeing a confusion matrix, etc.\n",
    "\n",
    "The predictions usually reach values in the range 75% accuracy and higher. The best result so far from this notebook was 78.7% accuracy in predicting survival."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d653b1-3b9a-429e-80e0-02bd16de722e",
   "metadata": {},
   "source": [
    "## Preamble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8513bd32-b465-4ded-8bd1-75315990d233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Preprocessing allows us to standarsize our data\n",
    "from sklearn import preprocessing\n",
    "# Allows us to split our data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Allows us to test parameters of classification algorithms and find the best one\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Logistic Regression classification algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Support Vector Machine classification algorithm\n",
    "from sklearn.svm import SVC\n",
    "# Decision Tree classification algorithm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# K Nearest Neighbors classification algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Multilayer Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09df1bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting this option will print all collumns of a dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Setting this option will print all of the data in a feature\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2bf13b-19b1-43d6-a2cd-d2f20bd69fb5",
   "metadata": {},
   "source": [
    "This function is to plot the confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f30279e-9d5e-4df5-a814-8053d099c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y,y_predict):\n",
    "    \"this function plots the confusion matrix\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    cm = confusion_matrix(y, y_predict)\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, cmap ='Greens', annot=True, linewidths = 0.5, \n",
    "                linecolor='black',ax = ax); #annot=True to annotate cells\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    ax.xaxis.set_ticklabels(['0', '1']); ax.yaxis.set_ticklabels(['0', '1']) \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96fe41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the value of the confusion matrix\n",
    "def cm_res(Y_t, Y_hat):\n",
    "    cm_a = confusion_matrix(Y_t, Y_hat)\n",
    "    tp = cm_a[1][1]\n",
    "    tn = cm_a[0][0]\n",
    "    fp = cm_a[0][1]\n",
    "    fn = cm_a[1][0]\n",
    "    return tp, tn, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3784f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this prepares for the overview, shows the confusion matrix\n",
    "def overw(X, Y, Y_hat, fitter):\n",
    "    plot_confusion_matrix(Y,Y_hat)\n",
    "    a = fitter.score(X, Y)\n",
    "    b = metrics.f1_score(Y, Y_hat)\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0abf51b-e8f8-4fa5-8275-1205554ba883",
   "metadata": {},
   "source": [
    "## Load and prepare the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1630e1",
   "metadata": {},
   "source": [
    "### Training / test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d70145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the training data\n",
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da358454",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1a2d076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6342708c",
   "metadata": {},
   "source": [
    "X was downloaded, we will see later what is the use of it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae214975",
   "metadata": {},
   "source": [
    "In this dataset, the variable we want to predict is \"Survived\" - so that is our \"Y\", the rest (TBD which variables) is our \"X\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d35ed-ebae-4e84-8c60-935e3a699346",
   "metadata": {},
   "source": [
    "Create a NumPy array from the column <code>Survived</code> in <code>data</code>, by applying the method <code>to_numpy()</code>  then\n",
    "assign it  to the variable <code>Y</code>, make sure the output is a Pandas series (only one bracket df\\['name of  column']).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42ce92bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = \"SibSp\"\n",
    "disc = True\n",
    "b = 20\n",
    "\n",
    "df_w = data[data[\"Survived\"]==1]\n",
    "df_w2 = data[data[\"Survived\"]==0]\n",
    "\n",
    "fig, axa = plt.subplots(ncols = 2, figsize = (8,3), sharey = True)\n",
    "fig.tight_layout(pad=2.0)\n",
    "    \n",
    "sns.histplot(data = df_w, x = r1, stat = 'percent',\n",
    "            kde = False, bins = b, discrete = disc, fill = False,\n",
    "            ax=axa[0])\n",
    "\n",
    "sns.histplot(data = df_w2, x = r1, stat = 'percent',\n",
    "            kde = False, bins = b, discrete = disc, fill = False,\n",
    "            ax=axa[1])\n",
    "\n",
    "axa[0].set_title(\"Survived\")\n",
    "axa[1].set_title(\"Not survived\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af807e0",
   "metadata": {},
   "source": [
    "Note: by examining the different variables, it becomes clear that some have a strong correlation with the outcome, while others have a less clear correlation.\n",
    "\n",
    "- Strong: Pclass, Sex, Embarked \n",
    "- Weak: SibSp, Parch, Fare\n",
    "- Inconclusive: Age\n",
    "\n",
    "We will then work with the data accordingly.\n",
    "\n",
    "After several trials, I observed that removing some of the data from the train/test set had a beter effect on the prediction than trying to create \"synthetic data\" to fill the gaps. However, for the set we want to predict, we will fill the gaps with a bit more sophisticated synthetic data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b89760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "variables = [\"Pclass\", \"Sex\", \"Embarked\", \"SibSp\", \"Parch\", \"Fare\", \"Age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e46295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a DF with the subset of variables that we care about - we will clean this up and use to feed the model\n",
    "data_w = pd.DataFrame(data, columns = [\"Survived\"] + variables)\n",
    "data_w.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dca92797",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1def2751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that \"Age\" has several NaN as value -- we need to sort this out\n",
    "data_w.dropna(axis = 0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbb376f",
   "metadata": {},
   "source": [
    "Most of the NaNs (but not all) come from the column \"Age\". We will simply drop the NaN outright and train the model with the resulting set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d405afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w = data_w.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d72b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233e4852",
   "metadata": {},
   "source": [
    "### Prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49aeee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the data for prediction\n",
    "data_p = pd.read_csv(\"test.csv\")   # we want to predict (\"p\") based on this dataset\n",
    "data_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d558f1e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# many NaN in this set\n",
    "data_p.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a3f249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb43aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_p = pd.DataFrame(data_p, columns = variables)\n",
    "data_w_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23f2b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "320bb7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_p.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196b0ec7",
   "metadata": {},
   "source": [
    "The simplest way to clean up the NaNs is to get the means and fill the NaNs with them.\n",
    "\n",
    "This probably limits the maximum accuracy, but we have to live with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36608d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_p_means = data_w_p.mean(numeric_only = True).to_dict()\n",
    "data_w_p_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eeafdff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_p = data_w_p.fillna(axis = 0, value = data_w_p_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8419848",
   "metadata": {},
   "source": [
    "At this point, both train/test and prediction sets are ready to be used (free of NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc193e6",
   "metadata": {},
   "source": [
    "## How different / similar are the trial/test ensemble and the predict ensemble?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f29fc564",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w[variables].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0642ad20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_w_p.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2601bfc",
   "metadata": {},
   "source": [
    "The distributions are al very similar (from simple inspection of mean, std, etc.) - however, it stands out that SibSp and Parch between the 2 datasets show some marked difference.\n",
    "\n",
    "This could be a moment to use KL Divergence to quantify the \"closeness\" of these distributions. However, we will not embark in this more complex work here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9397f5",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c75d04e",
   "metadata": {},
   "source": [
    "Since we are dealing with a classification problem (survive / does not survive) we will compare the folllwing models from scikit learn:\n",
    "\n",
    "- Logistic Regression\n",
    "- Support Vector Machine\n",
    "- Decision Tree\n",
    "- K Nearest Neighbors\n",
    "- Perceptron (neural network)\n",
    "\n",
    "We will use a grid search to fine-tune the hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9148d6",
   "metadata": {},
   "source": [
    "### First we scale the data, prepare to be be used directly into the algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc72dffc-1032-4a3a-b84f-d2968b3faffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data_w[\"Survived\"].to_numpy(copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29e54145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this dataset, what is the probability of survival? \n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9e0dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbffbf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat a dataframe that we will use as variables\n",
    "X_1 = data_w[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59a7e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbe67bd",
   "metadata": {},
   "source": [
    "Note that the number of rows (first value in shape) in Y and X_1 must match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa90ff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the input DF that convert category variables into booleans\n",
    "X_2 = pd.get_dummies(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ecbf337",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ed6d1-626f-4c23-bf84-efd98f797280",
   "metadata": {},
   "source": [
    "Standardize the data in <code>X</code> then reassign it to the variable  <code>X</code> using the transform provided below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9941056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all variables are floats\n",
    "X = X_2.astype(float) \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b721a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final step for X: center and scale it so we can feed it into the models without worrying about unit variance.\n",
    "# keep it in another variable to check it works before assigning it to X\n",
    "X_new = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X_new[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "450c355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_new.copy()\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9f35ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f007c0-65fe-408a-9af6-febef40b1e1b",
   "metadata": {},
   "source": [
    "We split the data into training and testing data using the  function  <code>train_test_split</code>.   The training data is divided into validation data, a second set used for training  data; then the models are trained and hyperparameters are selected using the function <code>GridSearchCV</code>.\n",
    "\n",
    "The training data and test data should be assigned to the following labels:\n",
    "\n",
    "<code>X_train, X_test, Y_train, Y_test</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bef9d582-2c05-4a6f-ac6a-125766d093c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we split 80/20, use as global variables when calling functions\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "print ('Train set:', X_train.shape,  Y_train.shape)\n",
    "print ('Test set:', X_test.shape,  Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58c5beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random state in the train_test_split so that the average survival rate is +- the same as in the full dataset\n",
    "print(Y.mean())\n",
    "print(Y_train.mean())\n",
    "print(Y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9fa1425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that we will use to fit the models to the data\n",
    "def fitting(model, params):\n",
    "    model_cv = GridSearchCV(model, params, cv = 10, verbose = 1)\n",
    "    model_cv.fit(X_train, Y_train)\n",
    "    print(\"tuned hpyerparameters :(best parameters) \",model_cv.best_params_)\n",
    "    print(\"accuracy :\",model_cv.best_score_)\n",
    "    return(model_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ceabdd",
   "metadata": {},
   "source": [
    "At this point, we feed Y and X into different models, train and test them, in the end we compare the models to choose the one that we will use to submit our predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eb8697",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de49af42-d4af-4f3b-bbbb-3b7cc6793c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "parameters ={\"C\":[0.05,1.0,1.5],'penalty':[\"l2\"], 'solver':['lbfgs']} # l1 lasso l2 ridge\n",
    "\n",
    "logreg_cv = fitting(lr, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8890f2b5-9f2a-478b-8772-078b2e55483d",
   "metadata": {},
   "source": [
    "Calculate the accuracy on the test data using the method <code>score</code>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70f4b3ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logreg_cv_scr, logreg_cv_F1 = overw(X_test, Y_test, logreg_cv.predict(X_test), logreg_cv)\n",
    "print(\"score = \", logreg_cv_scr, \"  F1 = \", logreg_cv_F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e8f80b-f9e9-43cc-8703-446e4032ce1a",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c963658",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "parameters = {'C': np.array([25, 33, 38]),  # need to play with it to get to best results\n",
    "              'gamma':np.array([0.01, 0.04, 0.06])}\n",
    "# use the default rbf kernel\n",
    "\n",
    "svm_cv = fitting(svm, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9ce870e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svm_cv_scr, svm_cv_F1 = overw(X_test, Y_test, svm_cv.predict(X_test), svm_cv)\n",
    "print(\"score = \", svm_cv_scr, \"  F1 = \", svm_cv_F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e0b51a-3ccd-49d4-a214-6ef189aedc2f",
   "metadata": {},
   "source": [
    "### Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d85a7713-82bc-4857-9a18-56f2f425abcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'criterion': ['gini', 'entropy'],\n",
    "     'splitter': ['best', 'random'],\n",
    "     'max_depth': [2*n for n in range(1,10)],\n",
    "     'max_features': ['auto', 'sqrt'],\n",
    "     'min_samples_leaf': [1, 2, 4],\n",
    "     'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "tree_cv = fitting(tree, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd8101f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_cv_scr, tree_cv_F1 = overw(X_test, Y_test, tree_cv.predict(X_test), tree_cv)\n",
    "print(\"score = \", tree_cv_scr, \"  F1 = \", tree_cv_F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612dbb58-fb2f-47ee-a7bb-d77a00e6dbd3",
   "metadata": {},
   "source": [
    "### K nearest neighbor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cee22b2-bcf7-471e-96cf-e63302a47b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "parameters = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'p': [1,2]}\n",
    "\n",
    "knn_cv = fitting(KNN, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07c26d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cv_scr, knn_cv_F1 = overw(X_test, Y_test, knn_cv.predict(X_test), knn_cv)\n",
    "print(\"score = \", knn_cv_scr, \"  F1 = \", knn_cv_F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b5e22",
   "metadata": {},
   "source": [
    "### Neural Network (perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3224ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier()\n",
    "parameters ={'solver':['lbfgs', 'adam']}\n",
    "\n",
    "nn_cv = fitting(nn, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85785eff",
   "metadata": {},
   "source": [
    "Calculate the accuracy on the test data using the method <code>score</code>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99214d75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn_cv_scr, nn_cv_F1 = overw(X_test, Y_test, nn_cv.predict(X_test), nn_cv)\n",
    "print(\"score = \", nn_cv_scr, \"  F1 = \", nn_cv_F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a2d1d-7ac3-458c-ba11-10f97d22e927",
   "metadata": {},
   "source": [
    "## Compare the models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e2da33c-70ca-46ae-98a7-9ed8cdb4dabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metr_dict = {'Model':['KNN', 'Tree', 'LR', 'SVM', 'NeuralN'],\n",
    "            'Best score':[knn_cv.best_score_, tree_cv.best_score_, logreg_cv.best_score_, svm_cv.best_score_, nn_cv.best_score_],\n",
    "             'Score': [knn_cv_scr, tree_cv_scr, logreg_cv_scr, svm_cv_scr, nn_cv_scr],\n",
    "             'F1' : [knn_cv_F1, tree_cv_F1, logreg_cv_F1, svm_cv_F1, nn_cv_F1]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2fe26f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Report = pd.DataFrame() # ensure it is clear\n",
    "Report = pd.DataFrame.from_dict(metr_dict)\n",
    "Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ddefdfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axa = plt.subplots(ncols = 2, figsize = (8,3), sharey = True)\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "sns.barplot(data=Report, x=\"Model\", y=\"F1\", ax = axa[1])\n",
    "\n",
    "sns.barplot(data=Report, x=\"Model\", y=\"Score\", ax = axa[0])\n",
    "\n",
    "axa[0].set_ylim(0.5, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40299017",
   "metadata": {},
   "source": [
    "## Time to predict..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7868427",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1_p = data_w_p\n",
    "X_2_p = pd.get_dummies(X_1_p)\n",
    "X_p = X_2_p.astype(float) # make sure all numbers are float\n",
    "X_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea4cd815",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05f63f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as before: center and scale it so we can feed it into the models without worrying about unit variance.\n",
    "X_p_new = preprocessing.StandardScaler().fit(X_p).transform(X_p)\n",
    "X_p_new[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25134a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_p = X_p_new.copy()\n",
    "type(X_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53cdb58",
   "metadata": {},
   "source": [
    "### Predictions from the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5399f175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# survey a model, get its prediction ready to save for upload\n",
    "def pred(mod, data_p, X_p):\n",
    "    Y_p = mod.predict(X_p)\n",
    "    # prepare the DF with the predictions\n",
    "    subm = pd.concat([pd.DataFrame(data_p, columns=[\"PassengerId\"]), pd.DataFrame({'Survived': Y_p})], axis=1)\n",
    "    print(\"Survival rates:\")\n",
    "    print(\"Total ensemble = \", Y.mean())\n",
    "    print(\"Train = \", Y_train.mean())\n",
    "    print(\"Test = \", Y_test.mean())\n",
    "    print(\"Prediction = \", Y_p.mean())\n",
    "    return(subm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7441c61d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subm_logreg = pred(logreg_cv, data_p, X_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc745d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_svm = pred(svm_cv, data_p, X_p)\n",
    "\n",
    "# NB: this one scored the highest accuracy with 78.8% (as reported by Kaggle after submision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37b4b401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subm_tree = pred(tree_cv, data_p, X_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ace86827",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_knn = pred(knn_cv, data_p, X_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "036a1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_NeuralN = pred(nn_cv, data_p, X_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "94f3c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a model to generate a submission\n",
    "\n",
    "subm = subm_svm  # model\n",
    "number = 1 # number of the this \"trial\", e.g. 20\n",
    "\n",
    "subm.to_csv(f\"submission_{number}.csv\", header = True, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
